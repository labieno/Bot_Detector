{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baeb20f3",
   "metadata": {},
   "source": [
    "# Proyecto Final - Código: Deteccion_de_Bots_en_Twitter_mediante_grafos_y_Machine_Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174d0d32",
   "metadata": {},
   "source": [
    "## 1. API Twitter - Acceso a usuarios, tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fb7d55",
   "metadata": {},
   "source": [
    "Claves recogidas de la API de Twitter: https://developer.twitter.com/en/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "\n",
    "consumer_key = \"\"\n",
    "consumer_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret = \"\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005767ec",
   "metadata": {},
   "source": [
    "Acceso a tweets públicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd11608",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd971e39",
   "metadata": {},
   "source": [
    "Acceso a la información en formato json de un usuario, por ejemplo @nike:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b26245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = api.me()\n",
    "# print(json.dumps(data._json, indent=2))\n",
    "\n",
    "data = api.get_user(\"nike\")\n",
    "print(json.dumps(data._json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a826a",
   "metadata": {},
   "source": [
    "Obtener followers de un usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bdcc9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data = api.followers(screen_name=\"nike\")\n",
    "#for user in data:\n",
    "#    print(json.dumps(user._json, indent=2))\n",
    "\n",
    "# La API de Twitter solo entrega información paginada o en grupo (20 resultados)\n",
    "# Para obtenerlos todos hay que utilizar la clase Cursor, especificando usuario y nº de followers a obtener:\n",
    "\n",
    "for user in tweepy.Cursor(api.followers, screen_name=\"nike\").items(50):\n",
    "    print(json.dumps(user._json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a59842",
   "metadata": {},
   "source": [
    "Obtener followees o friends (usuarios a los que sigue nuestra cuenta objetivo) con Cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4aeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in tweepy.Cursor(api.friends, screen_name=\"nike\").items(50):\n",
    "    print(json.dumps(user._json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab0513",
   "metadata": {},
   "source": [
    "Obtener timeline de tweets de un usuario; se espeficica cuántos con Cursor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c274fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.user_timeline, screen_name=\"nike\", tweet_mode=\"extended\").items(2):\n",
    "    print(json.dumps(tweet._json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3106ff",
   "metadata": {},
   "source": [
    "Buscar tweets que contengan una cadena (q=\"algo\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f24c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search, q=\"algo\", tweet_mode=\"extended\").items(10):\n",
    "    #print(json.dumps(tweet._json, indent=2))\n",
    "    print(tweet._json[\"full_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3cb70",
   "metadata": {},
   "source": [
    "## 2. Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff74d",
   "metadata": {},
   "source": [
    "### 2.1 Funciones para obtener ficheros json:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523b848",
   "metadata": {},
   "source": [
    "Se dispone de varias bases de datos, como dev.json, que dispone de 2365 entradas. Se quieren obtener los screen_name en un txt: \"screen_names.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"Twitbot20/dev.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    #screen_names = []\n",
    "    f = open(\"screen_names.txt\", \"w\")\n",
    "    for user in data:\n",
    "        f.write(user['profile']['screen_name'] +\"\\n\")\n",
    "    f.close()\n",
    "    json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303879b",
   "metadata": {},
   "source": [
    "Se recogen en un json (SNlabels.json) los screen_name y label (1 si es bot, 0 si es humano):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "list=[]\n",
    "with open(\"Twitbot20/dev.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for user in data:\n",
    "        list.append({'screen_name':user['profile']['screen_name'],'label':user['label']})\n",
    "    json_file.close()\n",
    "\n",
    "f = open(\"SNlabels.json\", \"w\")\n",
    "f.write(json.dumps(list))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "435a0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2365\n"
     ]
    }
   ],
   "source": [
    "with open(\"SNlabels.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    print(len(data))\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a0eb5",
   "metadata": {},
   "source": [
    "### 2.2 Saneamiento de los ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb27e73",
   "metadata": {},
   "source": [
    "Se obtiene un json con las cuentas que NO han sido eliminadas: \"SNlabelsSANEADO.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ba5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "list=[]\n",
    "\n",
    "with open(\"SNlabels.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for user in data:\n",
    "        # sleep para no saturar la API: rate_time_limit\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            api.get_user(user['screen_name'])\n",
    "            list.append({'screen_name':user['screen_name'],'label':user['label']})\n",
    "            print(user['screen_name'], user['label'])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "json_file.close()\n",
    "\n",
    "f = open(\"SNlabelsSANEADO.json\", \"w\")\n",
    "f.write(json.dumps(list))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3fcd9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2196\n"
     ]
    }
   ],
   "source": [
    "with open(\"SNlabelsSANEADO.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    print(len(data))\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c9c4b",
   "metadata": {},
   "source": [
    "Se obtienen un total de 2196 que no han sido eliminadas, entre las que hay bots y humanos. Todavía hay cuentas que no devolverán resultados (grafos dirigidos) porque llevan inactivas cierto tiempo. Estos casos se eliminarán sobre la marcha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a552276",
   "metadata": {},
   "source": [
    "### 2.3 Clases adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5201fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Gabrieliam/Twitter-graph-classification\n",
    "# https://towardsdatascience.com/python-detecting-twitter-bots-with-graphs-and-machine-learning-41269205ab07\n",
    "# https://botometer.osome.iu.edu/bot-repository/datasets.html\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "import sys\n",
    "import igraph\n",
    "import json\n",
    "import operator\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import networkx as nx\n",
    "from karateclub import Graph2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97959661",
   "metadata": {},
   "source": [
    "https://gist.github.com/jdmoore7/51c048195b4fa1ddbd2ad3c56598a886\n",
    "class TweetGrabber():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/jdmoore7/51c048195b4fa1ddbd2ad3c56598a886\n",
    "class TweetGrabber():\n",
    "    \n",
    "    def __init__(self,myApi,sApi,at,sAt):\n",
    "        import tweepy\n",
    "        self.tweepy = tweepy\n",
    "        auth = tweepy.OAuthHandler(myApi, sApi)\n",
    "        auth.set_access_token(at, sAt)\n",
    "        self.api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)        \n",
    "        \n",
    "    def strip_non_ascii(self,string):\n",
    "        ''' Returns the string without non ASCII characters'''\n",
    "        stripped = (c for c in string if 0 < ord(c) < 127)\n",
    "        return ''.join(stripped)\n",
    "        \n",
    "    def keyword_search(self,keyword,csv_prefix):\n",
    "        import csv        \n",
    "        API_results = self.api.search(q=keyword,rpp=1000,show_user=True,tweet_mode='extended')\n",
    "\n",
    "        with open(f'{csv_prefix}.csv', 'w', newline='') as csvfile:\n",
    "            fieldnames = ['tweet_id', 'tweet_text', 'date', 'user_id', 'follower_count',\n",
    "                          'retweet_count','user_mentions']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for tweet in API_results:\n",
    "                text = self.strip_non_ascii(tweet.full_text)\n",
    "                date = tweet.created_at.strftime('%m/%d/%Y')        \n",
    "                writer.writerow({\n",
    "                                'tweet_id': tweet.id_str,\n",
    "                                'tweet_text': text,\n",
    "                                'date': date,\n",
    "                                'user_id': tweet.user.id_str,\n",
    "                                'follower_count': tweet.user.followers_count,\n",
    "                                'retweet_count': tweet.retweet_count,\n",
    "                                'user_mentions':tweet.entities['user_mentions']\n",
    "                                })        \n",
    "        \n",
    "    def user_search(self,user,csv_prefix):\n",
    "        import csv\n",
    "        API_results = self.tweepy.Cursor(self.api.user_timeline,id=user,tweet_mode='extended').items()\n",
    "\n",
    "        with open(f'{csv_prefix}.csv', 'w', newline='') as csvfile:\n",
    "            fieldnames = ['tweet_id', 'tweet_text', 'date', 'user_id', 'user_mentions', 'retweet_count']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for tweet in API_results:\n",
    "                text = self.strip_non_ascii(tweet.full_text)\n",
    "                date = tweet.created_at.strftime('%m/%d/%Y')        \n",
    "                writer.writerow({\n",
    "                                'tweet_id': tweet.id_str,\n",
    "                                'tweet_text': text,\n",
    "                                'date': date,\n",
    "                                'user_id': tweet.user.id_str,\n",
    "                                'user_mentions':tweet.entities['user_mentions'],\n",
    "                                'retweet_count': tweet.retweet_count\n",
    "                                }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece8e4b",
   "metadata": {},
   "source": [
    "https://gist.github.com/jdmoore7/f062916705494b51d8d625a910e9ea81\n",
    "class RetweetParser():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetweetParser():\n",
    "\n",
    "    def __init__(self,data,user):\n",
    "        import ast\n",
    "        self.user = user\n",
    "\n",
    "        edge_list = []\n",
    "\n",
    "        for idx,row in data.iterrows():\n",
    "            if len(row[4]) > 5:    \n",
    "                user_account = user\n",
    "                weight = np.log(row[5] + 1)\n",
    "                for idx_1, item in enumerate(ast.literal_eval(row[4])):\n",
    "                    edge_list.append((user_account,item['screen_name'],weight))\n",
    "\n",
    "                    for idx_2 in range(idx_1+1,len(ast.literal_eval(row[4]))):\n",
    "                        name_a = ast.literal_eval(row[4])[idx_1]['screen_name']\n",
    "                        name_b = ast.literal_eval(row[4])[idx_2]['screen_name']\n",
    "                        edge_list.append((name_a,name_b,weight))\n",
    "        import csv\n",
    "        with open(f'{self.user}.csv', 'w', newline='') as csvfile:\n",
    "            fieldnames = ['user_a', 'user_b', 'log_retweet']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            for row in edge_list:        \n",
    "                writer.writerow({\n",
    "                                'user_a': row[0],\n",
    "                                'user_b': row[1],\n",
    "                                'log_retweet': row[2]\n",
    "                                })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273dce98",
   "metadata": {},
   "source": [
    "https://gist.github.com/jdmoore7/074bc5adec23d2291cab945ab62c8a01\n",
    "class TweetGraph():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca536f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetGraph():\n",
    "    def __init__(self,edge_list):\n",
    "        import igraph\n",
    "        import pandas as pd\n",
    "        data = pd.read_csv(edge_list).to_records(index=False)\n",
    "        self.tuple_graph = igraph.Graph.TupleList(data, weights=True, directed=False)\n",
    "\n",
    "    def e_centrality(self):\n",
    "        import operator\n",
    "        vectors = self.tuple_graph.eigenvector_centrality()\n",
    "        e = {name:cen for cen, name in  zip([v for v in vectors],self.tuple_graph.vs['name'])}\n",
    "        return sorted(e.items(), key=operator.itemgetter(1),reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32384fed",
   "metadata": {},
   "source": [
    "## 3. Programa principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3e8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Se crea un objeto de tipo TweetGrabber\n",
    "\n",
    "t = TweetGrabber(\n",
    "    #consumer_key = \"\",\n",
    "    #consumer_secret = \"\",\n",
    "    #access_token = \"\",\n",
    "    #access_token_secret = \"\")\n",
    "    \n",
    "    myApi = \"\",\n",
    "    sApi = \"\",\n",
    "    at = \"\",\n",
    "    sAt = \"\")\n",
    "\n",
    "# Variable to hold whatever Twitter user is being classified\n",
    "screen_names = []\n",
    "# Se podría implementar la entrada de datos:\n",
    "# screen_name = sys.argv[1]\n",
    "\n",
    "# Se crea un objeto dataframe\n",
    "import pandas as pd\n",
    "df = pd.read_json(r'SNlabelsSANEADO.json')\n",
    "\n",
    "for i,j in df.iterrows():\n",
    "    screen_names.append(j['screen_name'])\n",
    "    \n",
    "# screen_names tiene los @user del json saneado\n",
    "\n",
    "# se mantiene constancia del índice para eliminar la fila que no devuelva info\n",
    "index = 0\n",
    "for screen_name in screen_names: \n",
    "    try:\n",
    "        existing_gml = igraph.read(screen_name + \".gml\")\n",
    "        print(screen_name + \".gml already exists.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            print(\"*Trabajando en \" + screen_name + \"*\")\n",
    "            # Se almacenan en un screen_name.csv las menciones con ese usuario\n",
    "            t.user_search(user=screen_name, csv_prefix=screen_name)\n",
    "\n",
    "            # Se crea un DataFrame a partir del csv para alimentar a RetweetParser\n",
    "            userFrame = pd.read_csv(screen_name + \".csv\")\n",
    "            \n",
    "            # RetweetParser sobreescribe el csv con un grafo conderado (lista con nodos y vectores no dirigidos)\n",
    "            r = RetweetParser(userFrame, screen_name)\n",
    "\n",
    "            # Se crea un objeto iGraph ponderado no dirigido\n",
    "            log_graph = TweetGraph(edge_list=screen_name + \".csv\")\n",
    "            \n",
    "            # Se comprueba que el csv contiene información (la cuenta interactúa), si no es eliminado:\n",
    "            f = open(screen_name + \".csv\")\n",
    "            reader = csv.reader(f)\n",
    "            lines= len(list(reader))\n",
    "            f.close()\n",
    "            \n",
    "            if lines<2:\n",
    "                df.drop([index])\n",
    "                os.remove(screen_name + \".csv\")\n",
    "                print(\"***Se salta el user \" + screen_name + \"***\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            #Add 'size' attribute to each vertex based on its Eigencentrality\n",
    "            #NOTE: multiplying the value by some consistent large number creates a more intuitive\n",
    "            #plot, viewing-wise, but doesn't impact classification, since this change is applied\n",
    "            #to all vertices\n",
    "            for key, value in log_graph.e_centrality():\n",
    "                log_graph.tuple_graph.vs.find(name=key)['size'] = value*20\n",
    "\n",
    "            # Se guarda el grafo en un gml\n",
    "            log_graph.tuple_graph.write_gml(f=screen_name+\".gml\")\n",
    "\n",
    "            # Se almacenan imágenes de los grafos:\n",
    "            \n",
    "            style = {}\n",
    "            style[\"edge_curved\"] = False\n",
    "            style[\"vertex_label\"] = log_graph.tuple_graph.vs['name']\n",
    "            style[\"vertex_label_size\"] = 5\n",
    "\n",
    "            igraph.plot(log_graph.tuple_graph, **style, target = screen_name+\".png\")\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(screen_name+\" falló\")\n",
    "            continue\n",
    "\n",
    "    index+=1\n",
    "    print(\"*Se ha completado el user \" + screen_name +\"*\")\n",
    "    \n",
    "print(len(df))\n",
    "# Se va a crear un 'SNlabelsV3.json' donde se mantienen aquellas cuentas de las que se ha creado el grafo\n",
    "df\n",
    "df.to_json('SNlabelsV3.json', orient = 'split', compression = 'infer', index = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d116ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "893bc039",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b838da97",
   "metadata": {},
   "source": [
    "### 4.1 Creación de grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b4376",
   "metadata": {},
   "source": [
    "Se crea el grafo embedded para cada @user (bot o humano). Se guarda en un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c3c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambiar por SNlabelsV3.json cuando se tenga para menos iteraciones\n",
    "\n",
    "dfm = None\n",
    "\n",
    "with open('SNlabelsSANEADO.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "for i in data:\n",
    "    try:\n",
    "        screen_name = i['screen_name']\n",
    "        #insert a line manually labeling \n",
    "        #each as a multigraph with this very messy chunk of code.\n",
    "        igraph_gml = open(screen_name+\".gml\", 'r')\n",
    "        lof = igraph_gml.readlines()\n",
    "        \n",
    "        if lof[4]!=\"multigraph 1\":\n",
    "          lof.insert(4, \"multigraph 1\\n\")\n",
    "        igraph_gml = open(screen_name + '.gml', 'w')\n",
    "        \n",
    "        lof = \"\".join(lof)\n",
    "        igraph_gml.write(lof)\n",
    "        igraph_gml.close()\n",
    "        \n",
    "        #Next, read the GML with NetworkX, then convert each\n",
    "        #node from being labeled by name to being labeled by sequential\n",
    "        #integers, since Graph2Vec requires nodes to be labeled this way\n",
    "        H = nx.read_gml(screen_name + '.gml', label='name')\n",
    "        convertedgraph = nx.convert_node_labels_to_integers(H)\n",
    "        \n",
    "        #Instantiate a Graph2Vec embedding model. There are\n",
    "        #a variety of parameters that can be changed when \n",
    "        #instantiating the model (see the above link to the Karate Club library),\n",
    "        #but I found 64 feature columns and otherwise default parameters\n",
    "        #to provide the best results\n",
    "        embedding_model = Graph2Vec(dimensions=64)\n",
    "\n",
    "        #Now, fit the model to the NetworkX graph, and store the embedding\n",
    "        #in a pandas DataFrame\n",
    "        embedding_model.fit([convertedgraph])\n",
    "        embeddingsframe = pd.DataFrame(embedding_model.get_embedding())\n",
    "        embeddingsframe['64'] = i['label']\n",
    "\n",
    "        #print(embeddingsframe)\n",
    "        if dfm is None:\n",
    "            dfm = embeddingsframe\n",
    "        else:\n",
    "            dfm = dfm.append(embeddingsframe, ignore_index = True, sort=False)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "dfm\n",
    "dfm.to_csv(r'../vectors_and_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd060ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012712</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>-0.012195</td>\n",
       "      <td>-0.013502</td>\n",
       "      <td>-0.007205</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>-0.010604</td>\n",
       "      <td>-0.013454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013784</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>-0.014770</td>\n",
       "      <td>-0.003902</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>-0.000912</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291312</td>\n",
       "      <td>0.341479</td>\n",
       "      <td>0.291104</td>\n",
       "      <td>-0.279474</td>\n",
       "      <td>-0.309417</td>\n",
       "      <td>-0.165109</td>\n",
       "      <td>-0.156161</td>\n",
       "      <td>0.167894</td>\n",
       "      <td>-0.243019</td>\n",
       "      <td>-0.308323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315874</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>-0.338477</td>\n",
       "      <td>-0.089411</td>\n",
       "      <td>0.130846</td>\n",
       "      <td>-0.020889</td>\n",
       "      <td>0.178775</td>\n",
       "      <td>0.128592</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.027486</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>-0.024905</td>\n",
       "      <td>-0.013290</td>\n",
       "      <td>-0.012569</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>-0.019561</td>\n",
       "      <td>-0.024817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>0.010716</td>\n",
       "      <td>-0.027244</td>\n",
       "      <td>-0.007197</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.014390</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161980</td>\n",
       "      <td>0.189875</td>\n",
       "      <td>0.161864</td>\n",
       "      <td>-0.155398</td>\n",
       "      <td>-0.172047</td>\n",
       "      <td>-0.091807</td>\n",
       "      <td>-0.086831</td>\n",
       "      <td>0.093355</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.171439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175637</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>-0.188205</td>\n",
       "      <td>-0.049716</td>\n",
       "      <td>0.072755</td>\n",
       "      <td>-0.011615</td>\n",
       "      <td>0.099405</td>\n",
       "      <td>0.071502</td>\n",
       "      <td>0.089742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>-0.015404</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>-0.009101</td>\n",
       "      <td>-0.008607</td>\n",
       "      <td>0.009254</td>\n",
       "      <td>-0.013395</td>\n",
       "      <td>-0.016994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017411</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>-0.018656</td>\n",
       "      <td>-0.004928</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.009854</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>0.023691</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>0.023674</td>\n",
       "      <td>-0.022729</td>\n",
       "      <td>-0.025164</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>-0.012700</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>-0.025075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025689</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>-0.027527</td>\n",
       "      <td>-0.007272</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>-0.012449</td>\n",
       "      <td>-0.013783</td>\n",
       "      <td>-0.007355</td>\n",
       "      <td>-0.006956</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>-0.010825</td>\n",
       "      <td>-0.013734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.005930</td>\n",
       "      <td>-0.015077</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>0.445575</td>\n",
       "      <td>0.522309</td>\n",
       "      <td>0.445258</td>\n",
       "      <td>-0.427470</td>\n",
       "      <td>-0.473268</td>\n",
       "      <td>-0.252542</td>\n",
       "      <td>-0.238855</td>\n",
       "      <td>0.256802</td>\n",
       "      <td>-0.371709</td>\n",
       "      <td>-0.471596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483143</td>\n",
       "      <td>0.203637</td>\n",
       "      <td>-0.517716</td>\n",
       "      <td>-0.136759</td>\n",
       "      <td>0.200135</td>\n",
       "      <td>-0.031951</td>\n",
       "      <td>0.273445</td>\n",
       "      <td>0.196688</td>\n",
       "      <td>0.246863</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>0.012581</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>-0.013363</td>\n",
       "      <td>-0.007131</td>\n",
       "      <td>-0.006744</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>-0.010496</td>\n",
       "      <td>-0.013316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>-0.014618</td>\n",
       "      <td>-0.003862</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>-0.000902</td>\n",
       "      <td>0.007721</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>0.444887</td>\n",
       "      <td>0.521503</td>\n",
       "      <td>0.444570</td>\n",
       "      <td>-0.426810</td>\n",
       "      <td>-0.472537</td>\n",
       "      <td>-0.252153</td>\n",
       "      <td>-0.238486</td>\n",
       "      <td>0.256406</td>\n",
       "      <td>-0.371135</td>\n",
       "      <td>-0.470867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482398</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>-0.516918</td>\n",
       "      <td>-0.136548</td>\n",
       "      <td>0.199826</td>\n",
       "      <td>-0.031902</td>\n",
       "      <td>0.273023</td>\n",
       "      <td>0.196384</td>\n",
       "      <td>0.246482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1912 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.012712  0.014901  0.012703 -0.012195 -0.013502 -0.007205 -0.006814   \n",
       "1     0.291312  0.341479  0.291104 -0.279474 -0.309417 -0.165109 -0.156161   \n",
       "2     0.023448  0.027486  0.023431 -0.022495 -0.024905 -0.013290 -0.012569   \n",
       "3     0.161980  0.189875  0.161864 -0.155398 -0.172047 -0.091807 -0.086831   \n",
       "4     0.016057  0.018822  0.016045 -0.015404 -0.017055 -0.009101 -0.008607   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1907  0.023691  0.027771  0.023674 -0.022729 -0.025164 -0.013428 -0.012700   \n",
       "1908  0.012976  0.015211  0.012967 -0.012449 -0.013783 -0.007355 -0.006956   \n",
       "1909  0.445575  0.522309  0.445258 -0.427470 -0.473268 -0.252542 -0.238855   \n",
       "1910  0.012581  0.014748  0.012572 -0.012070 -0.013363 -0.007131 -0.006744   \n",
       "1911  0.444887  0.521503  0.444570 -0.426810 -0.472537 -0.252153 -0.238486   \n",
       "\n",
       "             7         8         9  ...        55        56        57  \\\n",
       "0     0.007326 -0.010604 -0.013454  ...  0.013784  0.005810 -0.014770   \n",
       "1     0.167894 -0.243019 -0.308323  ...  0.315874  0.133135 -0.338477   \n",
       "2     0.013514 -0.019561 -0.024817  ...  0.025425  0.010716 -0.027244   \n",
       "3     0.093355 -0.135127 -0.171439  ...  0.175637  0.074028 -0.188205   \n",
       "4     0.009254 -0.013395 -0.016994  ...  0.017411  0.007338 -0.018656   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1907  0.013654 -0.019764 -0.025075  ...  0.025689  0.010827 -0.027527   \n",
       "1908  0.007479 -0.010825 -0.013734  ...  0.014070  0.005930 -0.015077   \n",
       "1909  0.256802 -0.371709 -0.471596  ...  0.483143  0.203637 -0.517716   \n",
       "1910  0.007251 -0.010496 -0.013316  ...  0.013642  0.005750 -0.014618   \n",
       "1911  0.256406 -0.371135 -0.470867  ...  0.482398  0.203322 -0.516918   \n",
       "\n",
       "            58        59        60        61        62        63  64  \n",
       "0    -0.003902  0.005710 -0.000912  0.007801  0.005611  0.007043   0  \n",
       "1    -0.089411  0.130846 -0.020889  0.178775  0.128592  0.161396   1  \n",
       "2    -0.007197  0.010532 -0.001681  0.014390  0.010350  0.012991   0  \n",
       "3    -0.049716  0.072755 -0.011615  0.099405  0.071502  0.089742   1  \n",
       "4    -0.004928  0.007212 -0.001151  0.009854  0.007088  0.008896   0  \n",
       "...        ...       ...       ...       ...       ...       ...  ..  \n",
       "1907 -0.007272  0.010641 -0.001699  0.014539  0.010458  0.013126   0  \n",
       "1908 -0.003983  0.005828 -0.000930  0.007963  0.005728  0.007189   1  \n",
       "1909 -0.136759  0.200135 -0.031951  0.273445  0.196688  0.246863   1  \n",
       "1910 -0.003862  0.005651 -0.000902  0.007721  0.005554  0.006970   0  \n",
       "1911 -0.136548  0.199826 -0.031902  0.273023  0.196384  0.246482   1  \n",
       "\n",
       "[1912 rows x 65 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc8ced3",
   "metadata": {},
   "source": [
    "### 4.2 Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fcade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "\n",
    "dataset = pd.read_csv('../tfe (copia)/vectors_and_labels.csv')\n",
    "\n",
    "#Splitting data into input (vectors) and target (labels) datasets\n",
    "X = dataset.drop(columns=['64'])\n",
    "Y = dataset['64']\n",
    "#print(df.iloc[0])\n",
    "#print(X.iloc[0])\n",
    "#type(X.iloc[0])\n",
    "\n",
    "#Splitting these datasets further into training and test datasets.\n",
    "#This prevents contamination, i.e. the model learning from the labels\n",
    "#it's later going to try to predict. If you had the answers to a test\n",
    "#while you were studying for it, your grade on the test wouldn't really\n",
    "#be an accurate representation of how well you'd studied, would it? , early_stopping_rounds = 10\n",
    "seed = 42\n",
    "test_size = 0.4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "#Create a classification model with set parameters, and fit it to the\n",
    "#training data. This can take a little while, depending on your parameters\n",
    "model = xgb.XGBClassifier(objective=\"binary:hinge\", random_state=42, learning_rate = 0.05, n_estimators = 5000, early_stopping_rounds = 10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "#Test your model's accuracy by making a prediction on the test set\n",
    "#that we've separated, and print that accuracy score\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97e872",
   "metadata": {},
   "source": [
    "## 5. Predicción para un usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d991fa5b",
   "metadata": {},
   "source": [
    "### 5.1 Creación del grafo (csv y gml) del usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ffe9f8",
   "metadata": {},
   "source": [
    "Se crea el grafo del usuario y se procesa para poder realizar la predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "178bac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name = \"Killensteak \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TweetGrabber(\n",
    "    myApi = \"\",\n",
    "    sApi = \"\",\n",
    "    at = \"\",\n",
    "    sAt = \"\")\n",
    "\n",
    "\n",
    "\n",
    "t.user_search(user=screen_name, csv_prefix=screen_name)\n",
    "\n",
    "userFrame = pd.read_csv(screen_name + \".csv\")\n",
    "\n",
    "r = RetweetParser(userFrame, screen_name)\n",
    "\n",
    "log_graph = TweetGraph(edge_list= screen_name + \".csv\")\n",
    "\n",
    "for key, value in log_graph.e_centrality():\n",
    "    log_graph.tuple_graph.vs.find(name=key)['size'] = value*20\n",
    "\n",
    "log_graph.tuple_graph.write_gml(f=screen_name+\".gml\")\n",
    "\n",
    "# Representación:\n",
    "\n",
    "style = {}\n",
    "style[\"edge_curved\"] = False\n",
    "style[\"vertex_label\"] = log_graph.tuple_graph.vs['name']\n",
    "style[\"vertex_label_size\"] = 5\n",
    "\n",
    "igraph.plot(log_graph.tuple_graph, **style, target = screen_name+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "645e5efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "igraph_gml = open(screen_name+\".gml\", 'r')\n",
    "lof = igraph_gml.readlines()\n",
    "igraph_gml.close()\n",
    "if lof[4]!=\"multigraph 1\":\n",
    "  lof.insert(4, \"multigraph 1\\n\")\n",
    "igraph_gml = open(screen_name + '.gml', 'w')\n",
    "lof = \"\".join(lof)\n",
    "igraph_gml.write(lof)\n",
    "igraph_gml.close()\n",
    "H = nx.read_gml(screen_name + '.gml', label='name')\n",
    "convertedgraph = nx.convert_node_labels_to_integers(H)\n",
    "\n",
    "embedding_model = Graph2Vec(dimensions=64)\n",
    "\n",
    "embedding_model.fit([convertedgraph])\n",
    "embeddingsframe = pd.DataFrame(embedding_model.get_embedding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486da5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc082a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(embeddingsframe)\n",
    "print(screen_name + ': ' + str(pred[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
